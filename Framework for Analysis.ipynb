{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import keyring\n",
    "import requests\n",
    "\n",
    "import fitbit\n",
    "import gather_keys_oauth2 as Oauth2\n",
    "import pandas as pd \n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Flow\n",
    "1. Set up authorization for using the FitBit API.\n",
    "2. Pull data from FitBit into a list of dictionaries ('activity_data') for a particular endpoint.\n",
    "3. Prepare an endpoint data frame for analysis. \n",
    "4. Analyze.\n",
    "\n",
    "### Alternative - use data in CSV file instead of connecting to FitBit\n",
    "If you analyzing FitBit data stored in a CSV file:\n",
    "1. Skip Steps 1, 2 and 3 in the process flow above \n",
    "2. Go to \"3 Alternative\" set of functions to read the CSV data and create the endpoint data frame structure. \n",
    "3. Continue with Step 4 to start your analysis. \n",
    "\n",
    "An example CSV file is in the repository: example_sleep.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Set up authorization for using the FitBit API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to set up authorization for the FitBit API. These instructions show you how to set up Fitbit so that you can connect to their api. \n",
    "\n",
    "https://towardsdatascience.com/collect-your-own-fitbit-data-with-python-ff145fa10873\n",
    "\n",
    "At the moment, the first chunk of the code in this notebook is copied directly from this post.\n",
    "\n",
    "\n",
    "When the directions mention secrets and keys, you'll notice that the code has in this notebook has stored the key and secret using the keyring library. This library helps you manage your keys and IDs (so that if you share your code, you don't share your credentials!).\n",
    "\n",
    "Here's a great link on how/why to use the keyring library.\n",
    "\n",
    "https://alexwlchan.net/2016/11/you-should-use-keyring/\n",
    "\n",
    "One last thing to note is that while we import the fitbit library, we're really only using it for authentication. In other words, we stop following the instruction after step two. Why is this? The fitbit python library calls the fitbit api in units of one day. And the fitbit api limits a single user's calls to 150 per hour, which means that if we used this library, we'd be limited to grabbing only 5 months of data at a time. \n",
    "\n",
    "Instead, we're going to create some functions that interact directly with the fitbit API so that we can grab a range of days' worth of data at a time.\n",
    "\n",
    "To be clear, sometimes you might want to get a single day's worth of data (and there's some code that does exactly that at the bottom of this notebook, but for this analysis, I'm more interested in trends across days than within days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = keyring.get_password(\"fitbit\", \"key\")\n",
    "CLIENT_SECRET = keyring.get_password(\"fitbit\", \"secret\")\n",
    "\n",
    "server = Oauth2.OAuth2Server(CLIENT_ID, CLIENT_SECRET)\n",
    "server.browser_authorize()\n",
    "ACCESS_TOKEN = str(server.fitbit.client.session.token['access_token'])\n",
    "REFRESH_TOKEN = str(server.fitbit.client.session.token['refresh_token'])\n",
    "auth2_client = fitbit.Fitbit(CLIENT_ID, CLIENT_SECRET, oauth2=True, access_token=ACCESS_TOKEN, refresh_token=REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're authorized to pull data from the Fitbit API. If you've never interacted with an api before, that won't keep you from moving forward with this analysis. Here's the only pieces of information you'll need to understand for this analysis:\n",
    "\n",
    "1. APIs are tools that entities to provide to allow your program to connect directly to their data. It's how we request data instead of using a UI interface. In Fitbit's case, the API provides more complete and detailed access to your data than is available in the UI download interface.\n",
    "\n",
    "2. APIs let you 'get', 'post', 'delete', and 'patch'(edit) data. We'll only 'get' data, using the python 'requests' library.\n",
    "\n",
    "3. Well-designed APIs use consistent URL formats to structure API calls. This takes the form of a URL. Getting, posting (etc.) data involves:\n",
    "    1. using the correct verb from the requests library (get, post, etc.)\n",
    "    2. structuring the text of the URL to meet the pattern that the API in question uses.\n",
    "\n",
    "\n",
    "Here's an example URL from the Fitbit api\n",
    " \"https://api.fitbit.com/1.2/user/-/sleep/date/2018-04-02/2018-04-08.json\"\n",
    " \n",
    "This breaks down into the following pattern:\n",
    "\n",
    "\"https://api.fitbit.com/1.2/user/-/\" + endpoint + \"/date/\" + start_date + \"/\" + end_date + \".json\"\n",
    "\n",
    "We'll use this to build a generic function that takes the endpoint name, start_date, and end_date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that other APIs might be able to do that the Fitbit API cannot:\n",
    "    \n",
    "    -Handle queries about the data: for example, we can't ask the Fitbit API questions like \"How many days in the past month have I slept less than 6 hours?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Pull data from FitBit into a list of dictionaries ('activity_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getEndpointData is a generic function that lets us retrieve data from any fitbit api endpoint we want\n",
    "def getEndpointData(endpoint, start_date, end_date):\n",
    "    # At some point, we should insert some defensive coding here to make sure that the start_date and \n",
    "    # end_date are provided in the proper format (YYYY-MM-DD e.g. '2018-04-28'). For now, we'll \n",
    "    # leave it to the user to know the correct format\n",
    "    \n",
    "    url = \"https://api.fitbit.com/1.2/user/-/\" + endpoint + \"/date/\" + start_date + \"/\" + end_date + \".json\"\n",
    "    results = requests.get(url = url, headers={'Authorization':'Bearer ' + ACCESS_TOKEN})\n",
    "    if results.status_code == 200:\n",
    "        activity_data = json.loads(results.text)\n",
    "        return activity_data\n",
    "    else:\n",
    "        print(results.text)\n",
    "        return \"ERROR\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also build a function that makes our initial dates go backwards in time. This gives us an an easy way to loop back through all of the data we have stored in fitbit for a given endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right now this is set to assume we're pulling one month at a time. That's something \n",
    "# that it will probably make sense to change in the future.\n",
    "import datetime\n",
    "\n",
    "def makeDatesEarlier(start_date, end_date):\n",
    "    end_date = (datetime.datetime.strptime(end_date, \"%Y-%m-%d\") - datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "    start_date = (datetime.datetime.strptime(start_date, \"%Y-%m-%d\") - datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "    return start_date, end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try this out with some sleep data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"sleep\"\n",
    "\n",
    "end_date = \"2018-04-28\"\n",
    "start_date = \"2018-03-29\"\n",
    "\n",
    "activity_data = getEndpointData(endpoint, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Prepare an endpoint data frame for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSleepResults(activity_data, sleep_summaries, sleep_time_events_detail):\n",
    "\n",
    "    if not activity_data['sleep']:\n",
    "        # sleep endpoint no longer returns results\n",
    "        print(\"no more sleep data!\")\n",
    "        return sleep_summaries, sleep_time_events_detail, \"stop\"\n",
    "    else:\n",
    "        for sleep_event in activity_data['sleep']:\n",
    "            sleep_time_events_detail.append(sleep_event['levels']['data'])\n",
    "            del sleep_event['levels']['data']\n",
    "            try: \n",
    "                del sleep_event['levels']['shortData']\n",
    "            except:\n",
    "                pass\n",
    "                #this was a nap, so no shortData was available\n",
    "            sleep_summaries.append(sleep_event)\n",
    "    return sleep_summaries, sleep_time_events_detail, \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_time_events_detail = []\n",
    "sleep_summaries = []\n",
    "endpoint = \"sleep\"\n",
    "\n",
    "\n",
    "# start_date decrement month by 1, increment date by 1 \n",
    "end_date = \"2018-05-19\"\n",
    "start_date = \"2018-04-20\"\n",
    "    \n",
    "status = \"continue\"\n",
    "    \n",
    "while status == \"continue\":\n",
    "    activity_data = getEndpointData(endpoint, start_date, end_date)\n",
    "    if activity_data != \"ERROR\":\n",
    "        sleep_summaries, sleep_time_events_detail, status = processSleepResults(activity_data, sleep_summaries, sleep_time_events_detail)\n",
    "        start_date, end_date = makeDatesEarlier(start_date, end_date)\n",
    "        print(\"start date: {}, end date: {}\".format(start_date, end_date))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint((sleep_summaries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect date of end sleep time, which will always be the day after the activity time\n",
    "\n",
    "# for each sleep record, grab the 'endTime' and minutes_asleep, and deep_minutes - ['levels']['summary']['deep']['minutes']\n",
    "\n",
    "sleep_list = []\n",
    "\n",
    "#open question: naps?\n",
    "\n",
    "\n",
    "\n",
    "# make note later about disappointing 30-day-average bs\n",
    "\n",
    "for sleep_summary in sleep_summaries:\n",
    "    end_time = sleep_summary['endTime']\n",
    "    end_date, wakeup_time = end_time.split(\"T\")\n",
    "    wakeup_time = datetime.datetime.strptime(wakeup_time, \"%H:%M:%S.%f\").time()\n",
    "    start_time = sleep_summary['startTime']\n",
    "    start_date, bed_time = start_time.split(\"T\")\n",
    "    bed_time = datetime.datetime.strptime(bed_time, \"%H:%M:%S.%f\").time()\n",
    "    #convert end_date to a date instead of string\n",
    "    end_date = (datetime.datetime.strptime(end_date, \"%Y-%m-%d\")- datetime.timedelta(days=1)).date()\n",
    "    minutes_asleep = sleep_summary['minutesAsleep']\n",
    "    sleep_efficiency = sleep_summary['efficiency']\n",
    "    try:\n",
    "        deep_minutes = sleep_summary['levels']['summary']['deep']['minutes']\n",
    "        deep_count = sleep_summary['levels']['summary']['deep']['count']\n",
    "        \n",
    "        light_minutes = sleep_summary['levels']['summary']['light']['minutes']\n",
    "        light_count = sleep_summary['levels']['summary']['light']['count']\n",
    "        \n",
    "        \n",
    "        rem_minutes = sleep_summary['levels']['summary']['rem']['minutes']\n",
    "        rem_count = sleep_summary['levels']['summary']['rem']['count']        \n",
    "        \n",
    "        wake_minutes = sleep_summary['levels']['summary']['wake']['minutes']\n",
    "        wake_count = sleep_summary['levels']['summary']['wake']['count']\n",
    "        \n",
    "        sleep_list.append({'end_date': end_date, 'wakeup_time': wakeup_time, 'minutes_asleep': minutes_asleep,\\\n",
    "                          'deep_minutes': deep_minutes, 'deep_count': deep_count, \\\n",
    "                           'light_minutes': light_minutes, 'light_count': light_count, \\\n",
    "                           'rem_minutes': rem_minutes, 'rem_count': rem_count, \\\n",
    "                           'wake_minutes': wake_minutes, 'wake_count': wake_count, \\\n",
    "                           'efficiency': sleep_efficiency, 'start_data': start_date, 'bed_time': bed_time\n",
    "                          \n",
    "                          })\n",
    "    except:\n",
    "        # we're skipping nap data\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.DataFrame(sleep_list)\n",
    "print(sleep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 (CSV alternative) - Read FitBit data in from a CSV file\n",
    "To avoid running this portion inadvertantly, toggle the 'use_csv' boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_csv = False\n",
    "\n",
    "from tkinter import filedialog\n",
    "import csv\n",
    "\n",
    "def csv_to_list(csv_filename):\n",
    "    '''Return embedded list containing data in given CSV file.'''\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    with open(csv_filename) as f:\n",
    "        csv_f = csv.reader(f)\n",
    "        for row in csv_f:\n",
    "            result_list.append(row)\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "if not use_csv:\n",
    "    pass\n",
    "else:\n",
    "    # Build activity_list using CSV file\n",
    "    # Improve this by adding endpoint as a parameter so this function can be repeatable for any endpoint\n",
    "    \n",
    "    sleep_data = []\n",
    "    sleep_data = csv_to_list(filedialog.askopenfilename(title='Select FitBit CSV', filetypes=[(\"CSV\",\"*.csv\"),(\"All files\",\"*.*\")]))\n",
    "\n",
    "    # Cleanup by deleting first column which is an index\n",
    "    for x in sleep_data:\n",
    "        del x[0]\n",
    "        \n",
    "    # Convert sleep_data to sleep_list list of dictionaries to match 'fitbit messing around' data frame\n",
    "    sleep_summaries = sleep_data[1:]  # Don't include first list which is column headers\n",
    "    sleep_list = []\n",
    "\n",
    "    '''\n",
    "    For reference, this is the list of columns with example formats:\n",
    "    0 bed_time: 1900-01-01 23:17:00\n",
    "    1 deep_count: 4\n",
    "    2 deep_minutes: 58\n",
    "    3 efficiency: 98\n",
    "    4 end_date: 2017-06-09 00:00:00\n",
    "    5 light_count: 30\n",
    "    6 light_minutes: 258\n",
    "    7 minutes_asleep: 509\n",
    "    8 rem_count: 8\n",
    "    9 rem_minutes: 193\n",
    "    10 start_data: 2017-06-09\n",
    "    11 wake_count: 24\n",
    "    12 wake_minutes: 39\n",
    "    13 wakeup_time: 1900-01-01 08:25:30\n",
    "    '''\n",
    "\n",
    "    for sleep_summary in sleep_summaries:\n",
    "        bed_time = strip_time(sleep_summary[0])\n",
    "\n",
    "        sleep_list.append({\n",
    "            'bed_time': sleep_summary[0],\\\n",
    "            'deep_count': sleep_summary[1],\\\n",
    "            'deep_minutes': sleep_summary[2],\\\n",
    "            'efficiency': sleep_summary[3],\\\n",
    "            'end_date': sleep_summary[4],\\\n",
    "            'light_count': sleep_summary[5],\\\n",
    "            'light_minutes': sleep_summary[6],\\\n",
    "            'minutes_asleep': sleep_summary[7],\\\n",
    "            'rem_count': sleep_summary[8],\\\n",
    "            'rem_minutes': sleep_summary[9],\\\n",
    "            'start_data': sleep_summary[10],\\\n",
    "            'wake_count': sleep_summary[11],\\\n",
    "            'wake_minutes': sleep_summary[12],\\\n",
    "            'wakeup_time': sleep_summary[13]})\n",
    "        \n",
    "    sleep_df = pd.DataFrame(sleep_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sleep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df.to_csv(path_or_buf = \"melissa_sleep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sleep_df['efficiency'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sleep_df['deep_minutes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sleep_df['wake_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df[sleep_df['efficiency'] < 92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sleep_df['wake_minutes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our question: How is sleep impacted by activity level?\n",
    "\n",
    "veryActiveMinutes and fairlyActiveMinutes is how we're measuring activity level\n",
    "\n",
    "Do I have more deep sleep the more I am very and fairly active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sleep_df['minutes_asleep'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df['minutes_asleep'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Analysis for Sleep Endpoint\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Data Build and Analysis (steps 2-4) for Activity Endpoint(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertActiveMinuteData(data, endpoint):\n",
    "    data_list = []\n",
    "    \n",
    "    endpoint = endpoint.replace(r\"/\", \"-\")\n",
    "    column_name = endpoint.split(\"-\")[1]\n",
    "    for line in data[endpoint]:\n",
    "        data_list.append({'end_date': datetime.datetime.strptime(line['dateTime'], \"%Y-%m-%d\"), column_name: int(line['value'])})\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of activities endpoints for reference\n",
    "\n",
    "endpoints = [\"activities/calories\", \"activities/caloriesBMR\", \"activities/steps\", \"activities/distance\", \n",
    "             \"activities/floors\", \"activities/elevation\", \"activities/minutesSedentary\", \n",
    "             \"activities/minutesLightlyActive\", \"activities/minutesFairlyActive\", \"activities/minutesVeryActive\",\n",
    "            \"activities/activityCalories\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start_date = '2017-06-10' \n",
    "end_date = '2018-05-19'\n",
    "\n",
    "\n",
    "\n",
    "endpoint = \"activities/minutesVeryActive\"\n",
    "\n",
    "# first grab veryActiveMinutes\n",
    "veryActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "# grab date and minutes from veryActiveMinutes\n",
    "veryActiveList = convertActiveMinuteData(veryActiveData, endpoint)\n",
    "\n",
    "# then grab fairlyActiveMinutes\n",
    "endpoint = \"activities/minutesFairlyActive\"\n",
    "fairlyActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "#grab date and minutes from fairlyActiveMinutes\n",
    "fairlyActiveList = convertActiveMinuteData(fairlyActiveData, endpoint)\n",
    "\n",
    "\n",
    "endpoint = \"activities/minutesSedentary\"\n",
    "sedentaryActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "#grab date and minutes from fairlyActiveMinutes\n",
    "sedentaryActiveList = convertActiveMinuteData(sedentaryActiveData, endpoint)\n",
    "\n",
    "\n",
    "\n",
    "endpoint = \"activities/minutesLightlyActive\"\n",
    "lightlyActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "#grab date and minutes from fairlyActiveMinutes\n",
    "lightlyActiveList = convertActiveMinuteData(lightlyActiveData, endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activity score. \n",
    "# dailyminutes (1440) = sedentaryMinutes + all active minutes\n",
    "\n",
    "# of the waking time, how much was active, and how much was sedentary?\n",
    "\n",
    "# use average number of asleep minutes - 407 to subtract from sedentaryMinutes and dailyMinutes\n",
    "\n",
    "# what percentage of time was I active (out of awake minutes)?\n",
    "# all_active_minutes / (1440-407)\n",
    "\n",
    "# all_active_minutes / 1033\n",
    "\n",
    "def calculatePercent(input_list, target):\n",
    "    return target / sum(input_list) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_data = pd.merge(veryActiveList, fairlyActiveList, on='end_date')\n",
    "activity_data = pd.merge(activity_data, sedentaryActiveList, on='end_date')\n",
    "activity_data = pd.merge(activity_data, lightlyActiveList, on='end_date')\n",
    "activity_data = pd.merge(activity_data, sleep_df, on='end_date')\n",
    "\n",
    "activity_data = activity_data.fillna(0)\n",
    "\n",
    "print(activity_data)\n",
    "\n",
    "# Investigate data further using Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to see if very_active_minutes taken as a percent of total active time are \n",
    "# able to predict deep sleep\n",
    "\n",
    "\n",
    "activity_data['very_active_percent'] = activity_data.apply(lambda x: calculatePercent([x['minutesLightlyActive'], x['minutesVeryActive'], x['minutesFairlyActive']], x['minutesVeryActive']), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(activity_data['very_active_percent'], activity_data['deep_minutes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would seem that very_active_minutes are not a good predictor of the number of deep sleep minutes.\n",
    "\n",
    "Do very active minutes decrease the number of waking events during the night?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(activity_data['very_active_percent'], activity_data['wake_count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((activity_data['minutesVeryActive']+activity_data['minutesFairlyActive']),activity_data['deep_minutes']/activity_data['minutes_asleep'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"activities/heart\"\n",
    "end_date = \"2018-06-08\"\n",
    "start_date = \"2018-05-09\"\n",
    "\n",
    "heart_rate_data = getEndpointData(endpoint, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(heart_rate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pprint(heart_rate_data['activities-heart'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "heart_list = []\n",
    "\n",
    "for record in heart_rate_data['activities-heart']:\n",
    "    heart_dict = {}\n",
    "    heart_dict['resting_heart_rate'] = record['value']['restingHeartRate']\n",
    "    heart_dict['date_obj'] = datetime.datetime.strptime(record['dateTime'], \"%Y-%m-%d\").date()\n",
    "    heart_dict['date_str'] = record['dateTime']\n",
    "    for zone in record['value']['heartRateZones']:\n",
    "        minute_name = zone['name'] + \"_minutes\"\n",
    "        minutes = zone['minutes']\n",
    "        calories_name = zone['name'] + \"_calories\"\n",
    "        calories_out = zone['caloriesOut']\n",
    "        heart_dict[minute_name] = minutes\n",
    "        heart_dict[calories_name] = calories_out\n",
    "    heart_list.append(heart_dict)\n",
    "heart_df = pd.DataFrame(heart_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "plt.hist(heart_df['resting_heart_rate'], bins=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(heart_df['Fat Burn_minutes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(heart_df['Cardio_minutes'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(heart_df['Cardio_minutes'], heart_df['resting_heart_rate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have some code Melissa wrote to originally interact with the fitbit library (the one that runs into that 150 calls per hour limit.)  We're keeping the code here in case it's helpful as we're building out the other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yesterday2 = str((datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
    "#today = str(datetime.now().strftime(\"%Y%m%d\"))\n",
    "\n",
    "#yesterday2 = ((datetime.now() - timedelta(days=1)))\n",
    "#yesterday3 = (yesterday2 - timedelta(days=1))\n",
    "#print(yesterday3)\n",
    "\n",
    "current_day = \"2018-05-18\"\n",
    "\n",
    "\n",
    "'''\n",
    "These functions use the intra-day endpoint. \n",
    "\n",
    "CAUTION: Plan your calls wisely, or you will exceed 150 API calls per hour.\n",
    "\n",
    "'''\n",
    "\n",
    "#take a starting date and a total number of days as an input\n",
    "# day needs to be in YYYY-MM-DD format\n",
    "def pullFitBitData(start_date, days, call_type):\n",
    "    #insert date error checking laterz\n",
    "    print(\"Processing day: {}\".format(start_date))\n",
    "    current_date = start_date\n",
    "    activity_df, heartRate_df = buildActivityData(current_date)\n",
    "    day_counter = 0\n",
    "    while day_counter < days:\n",
    "        current_date = (datetime.datetime.strptime(current_date, \"%Y-%m-%d\") - datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        print(\"Processing day: {}\".format(current_date))\n",
    "        activity_df2, heartRate_df2 = buildActivityData(current_date)\n",
    "        activity_df = pd.concat([activity_df, activity_df2])\n",
    "        heartRate_df = pd.concat([heartRate_df, heartRate_df2])\n",
    "        day_counter += 1\n",
    "    print(\"Ended processing on {}.\".format(current_date))\n",
    "    return activity_df, heartRate_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sleep_time_events_detail.txt', 'w') as outfile:\n",
    "    json.dump(sleep_time_events_detail, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_statsHR = auth2_client.intraday_time_series('activities/heart', base_date=current_day, detail_level='15min')\n",
    "heartRateZones = (fit_statsHR['activities-heart'][0]['value']['heartRateZones'])\n",
    "\n",
    "'''\n",
    "column_names = heartRatePivot_df.columns.values\n",
    "new_column_names = []\n",
    "for name in column_names:\n",
    "    new_name = name[1].replace(' ', '_')+'.'+name[0]\n",
    "    new_column_names.append(new_name)\n",
    "heartRatePivot_df.columns = new_column_names\n",
    "print(heartRatePivot_df)\n",
    "'''\n",
    "\n",
    "\n",
    "def accumulateHeartData(current_day, heartRateZones):\n",
    "    date_dict = {'date': [current_day, current_day, current_day, current_day]}\n",
    "    date_df = pd.DataFrame(date_dict)\n",
    "    \n",
    "    heartRateZones_df = pd.DataFrame.from_records(heartRateZones)\n",
    "    heartRateZones_df['date'] = date_df['date']\n",
    "    heartRatePivot_df = heartRateZones_df.pivot(index='date', columns='name')\n",
    "    column_names = heartRatePivot_df.columns.values\n",
    "    new_column_names = []\n",
    "    for name in column_names:\n",
    "        new_name = name[1].replace(' ', '_')+'.'+name[0]\n",
    "        new_column_names.append(new_name)\n",
    "    heartRatePivot_df.columns = new_column_names\n",
    "    return heartRatePivot_df\n",
    "\n",
    "def buildActivityData(current_date):\n",
    "    activity_stats = auth2_client.activities(date=current_date)\n",
    "    pprint(activity_stats)\n",
    "    activity_stats = activity_stats['summary']\n",
    "    heartRateZones = activity_stats['heartRateZones']\n",
    "    heartRate_df = accumulateHeartData(current_date, heartRateZones)\n",
    "    del activity_stats['distances']\n",
    "    del activity_stats['heartRateZones']\n",
    "    activity_df = pd.DataFrame(activity_stats, index=[current_date])\n",
    "    return activity_df, heartRate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df, heartRate_df = buildActivityData(\"2018-05-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heartRate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_statsHR = auth2_client.intraday_time_series('activities/heart', base_date=current_day, detail_level='15min')\n",
    "pprint(fit_statsHR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
