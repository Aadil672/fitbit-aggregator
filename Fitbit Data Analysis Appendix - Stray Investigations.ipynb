{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains two sets of scraps accumulated through the project.\n",
    "\n",
    "First there's a section of functions and analysis to compare activity level endpoint data and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Data Build and Analysis (steps 2-4) for Activity Endpoint(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of activities endpoints for reference\n",
    "\n",
    "endpoints = [\"activities/calories\", \"activities/caloriesBMR\", \"activities/steps\", \"activities/distance\", \n",
    "             \"activities/floors\", \"activities/elevation\", \"activities/minutesSedentary\", \n",
    "             \"activities/minutesLightlyActive\", \"activities/minutesFairlyActive\", \"activities/minutesVeryActive\",\n",
    "            \"activities/activityCalories\"]\n",
    "\n",
    "\n",
    "\n",
    "def convertActiveMinuteData(data, endpoint):\n",
    "    data_list = []\n",
    "    \n",
    "    endpoint = endpoint.replace(r\"/\", \"-\")\n",
    "    column_name = endpoint.split(\"-\")[1]\n",
    "    for line in data[endpoint]:\n",
    "        data_list.append({'end_date': datetime.datetime.strptime(line['dateTime'], \"%Y-%m-%d\"), column_name: int(line['value'])})\n",
    "    df = pd.DataFrame(data_list)\n",
    "    return df\n",
    "\n",
    "import datetime\n",
    "\n",
    "start_date = '2017-06-10' \n",
    "end_date = '2018-05-19'\n",
    "\n",
    "\n",
    "\n",
    "endpoint = \"activities/minutesVeryActive\"\n",
    "\n",
    "# first grab veryActiveMinutes\n",
    "veryActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "# grab date and minutes from veryActiveMinutes\n",
    "veryActiveList = convertActiveMinuteData(veryActiveData, endpoint)\n",
    "\n",
    "# then grab fairlyActiveMinutes\n",
    "endpoint = \"activities/minutesFairlyActive\"\n",
    "fairlyActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "#grab date and minutes from fairlyActiveMinutes\n",
    "fairlyActiveList = convertActiveMinuteData(fairlyActiveData, endpoint)\n",
    "\n",
    "\n",
    "endpoint = \"activities/minutesSedentary\"\n",
    "sedentaryActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "#grab date and minutes from fairlyActiveMinutes\n",
    "sedentaryActiveList = convertActiveMinuteData(sedentaryActiveData, endpoint)\n",
    "\n",
    "\n",
    "\n",
    "endpoint = \"activities/minutesLightlyActive\"\n",
    "lightlyActiveData = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "#grab date and minutes from fairlyActiveMinutes\n",
    "lightlyActiveList = convertActiveMinuteData(lightlyActiveData, endpoint)\n",
    "\n",
    "# activity score. \n",
    "# dailyminutes (1440) = sedentaryMinutes + all active minutes\n",
    "\n",
    "# of the waking time, how much was active, and how much was sedentary?\n",
    "\n",
    "# use average number of asleep minutes - 407 to subtract from sedentaryMinutes and dailyMinutes\n",
    "\n",
    "# what percentage of time was I active (out of awake minutes)?\n",
    "# all_active_minutes / (1440-407)\n",
    "\n",
    "# all_active_minutes / 1033\n",
    "\n",
    "def calculatePercent(input_list, target):\n",
    "    return target / sum(input_list) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "activity_data = pd.merge(veryActiveList, fairlyActiveList, on='end_date')\n",
    "activity_data = pd.merge(activity_data, sedentaryActiveList, on='end_date')\n",
    "activity_data = pd.merge(activity_data, lightlyActiveList, on='end_date')\n",
    "activity_data = pd.merge(activity_data, sleep_df, on='end_date')\n",
    "\n",
    "activity_data = activity_data.fillna(0)\n",
    "\n",
    "print(activity_data)\n",
    "\n",
    "# Investigate data further using Tableau\n",
    "\n",
    "# Trying to see if very_active_minutes taken as a percent of total active time are \n",
    "# able to predict deep sleep\n",
    "\n",
    "\n",
    "activity_data['very_active_percent'] = activity_data.apply(lambda x: calculatePercent([x['minutesLightlyActive'], x['minutesVeryActive'], x['minutesFairlyActive']], x['minutesVeryActive']), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(activity_data['very_active_percent'], activity_data['deep_minutes'])\n",
    "plt.show()\n",
    "\n",
    "It would seem that very_active_minutes are not a good predictor of the number of deep sleep minutes.\n",
    "\n",
    "Do very active minutes decrease the number of waking events during the night?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(activity_data['very_active_percent'], activity_data['wake_count'])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter((activity_data['minutesVeryActive']+activity_data['minutesFairlyActive']),activity_data['deep_minutes']/activity_data['minutes_asleep'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "endpoint = \"activities/heart\"\n",
    "end_date = \"2018-06-08\"\n",
    "start_date = \"2018-05-09\"\n",
    "\n",
    "heart_rate_data = getEndpointData(endpoint, start_date, end_date)\n",
    "\n",
    "pprint(heart_rate_data)\n",
    "\n",
    "\n",
    "\n",
    "pprint(heart_rate_data['activities-heart'][0])\n",
    "\n",
    "import datetime\n",
    "\n",
    "heart_list = []\n",
    "\n",
    "for record in heart_rate_data['activities-heart']:\n",
    "    heart_dict = {}\n",
    "    heart_dict['resting_heart_rate'] = record['value']['restingHeartRate']\n",
    "    heart_dict['date_obj'] = datetime.datetime.strptime(record['dateTime'], \"%Y-%m-%d\").date()\n",
    "    heart_dict['date_str'] = record['dateTime']\n",
    "    for zone in record['value']['heartRateZones']:\n",
    "        minute_name = zone['name'] + \"_minutes\"\n",
    "        minutes = zone['minutes']\n",
    "        calories_name = zone['name'] + \"_calories\"\n",
    "        calories_out = zone['caloriesOut']\n",
    "        heart_dict[minute_name] = minutes\n",
    "        heart_dict[calories_name] = calories_out\n",
    "    heart_list.append(heart_dict)\n",
    "heart_df = pd.DataFrame(heart_list)\n",
    "\n",
    "print(heart_df)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "plt.hist(heart_df['resting_heart_rate'], bins=7)\n",
    "plt.show()\n",
    "\n",
    "plt.hist(heart_df['Fat Burn_minutes'])\n",
    "plt.show()\n",
    "\n",
    "plt.hist(heart_df['Cardio_minutes'])\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(heart_df['Cardio_minutes'], heart_df['resting_heart_rate'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have some code Melissa wrote to originally interact with the fitbit library (the one that runs into that 150 calls per hour limit.)  We're keeping the code here in case it's helpful as we're building out the other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yesterday2 = str((datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
    "#today = str(datetime.now().strftime(\"%Y%m%d\"))\n",
    "\n",
    "#yesterday2 = ((datetime.now() - timedelta(days=1)))\n",
    "#yesterday3 = (yesterday2 - timedelta(days=1))\n",
    "#print(yesterday3)\n",
    "\n",
    "current_day = \"2018-05-18\"\n",
    "\n",
    "\n",
    "'''\n",
    "These functions use the intra-day endpoint. \n",
    "\n",
    "CAUTION: Plan your calls wisely, or you will exceed 150 API calls per hour.\n",
    "\n",
    "'''\n",
    "\n",
    "#take a starting date and a total number of days as an input\n",
    "# day needs to be in YYYY-MM-DD format\n",
    "def pullFitBitData(start_date, days, call_type):\n",
    "    #insert date error checking laterz\n",
    "    print(\"Processing day: {}\".format(start_date))\n",
    "    current_date = start_date\n",
    "    activity_df, heartRate_df = buildActivityData(current_date)\n",
    "    day_counter = 0\n",
    "    while day_counter < days:\n",
    "        current_date = (datetime.datetime.strptime(current_date, \"%Y-%m-%d\") - datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        print(\"Processing day: {}\".format(current_date))\n",
    "        activity_df2, heartRate_df2 = buildActivityData(current_date)\n",
    "        activity_df = pd.concat([activity_df, activity_df2])\n",
    "        heartRate_df = pd.concat([heartRate_df, heartRate_df2])\n",
    "        day_counter += 1\n",
    "    print(\"Ended processing on {}.\".format(current_date))\n",
    "    return activity_df, heartRate_df\n",
    "        \n",
    "\n",
    "with open('sleep_time_events_detail.txt', 'w') as outfile:\n",
    "    json.dump(sleep_time_events_detail, outfile)\n",
    "\n",
    "fit_statsHR = auth2_client.intraday_time_series('activities/heart', base_date=current_day, detail_level='15min')\n",
    "heartRateZones = (fit_statsHR['activities-heart'][0]['value']['heartRateZones'])\n",
    "\n",
    "'''\n",
    "column_names = heartRatePivot_df.columns.values\n",
    "new_column_names = []\n",
    "for name in column_names:\n",
    "    new_name = name[1].replace(' ', '_')+'.'+name[0]\n",
    "    new_column_names.append(new_name)\n",
    "heartRatePivot_df.columns = new_column_names\n",
    "print(heartRatePivot_df)\n",
    "'''\n",
    "\n",
    "\n",
    "def accumulateHeartData(current_day, heartRateZones):\n",
    "    date_dict = {'date': [current_day, current_day, current_day, current_day]}\n",
    "    date_df = pd.DataFrame(date_dict)\n",
    "    \n",
    "    heartRateZones_df = pd.DataFrame.from_records(heartRateZones)\n",
    "    heartRateZones_df['date'] = date_df['date']\n",
    "    heartRatePivot_df = heartRateZones_df.pivot(index='date', columns='name')\n",
    "    column_names = heartRatePivot_df.columns.values\n",
    "    new_column_names = []\n",
    "    for name in column_names:\n",
    "        new_name = name[1].replace(' ', '_')+'.'+name[0]\n",
    "        new_column_names.append(new_name)\n",
    "    heartRatePivot_df.columns = new_column_names\n",
    "    return heartRatePivot_df\n",
    "\n",
    "def buildActivityData(current_date):\n",
    "    activity_stats = auth2_client.activities(date=current_date)\n",
    "    pprint(activity_stats)\n",
    "    activity_stats = activity_stats['summary']\n",
    "    heartRateZones = activity_stats['heartRateZones']\n",
    "    heartRate_df = accumulateHeartData(current_date, heartRateZones)\n",
    "    del activity_stats['distances']\n",
    "    del activity_stats['heartRateZones']\n",
    "    activity_df = pd.DataFrame(activity_stats, index=[current_date])\n",
    "    return activity_df, heartRate_df\n",
    "\n",
    "activity_df, heartRate_df = buildActivityData(\"2018-05-18\")\n",
    "\n",
    "print(activity_df)\n",
    "\n",
    "print(heartRate_df)\n",
    "\n",
    "fit_statsHR = auth2_client.intraday_time_series('activities/heart', base_date=current_day, detail_level='15min')\n",
    "pprint(fit_statsHR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
